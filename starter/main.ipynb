{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft-Module performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torchrl.policies as policies\n",
    "import torchrl.networks as networks\n",
    "from torchrl.utils import get_params\n",
    "from torchrl.algo import MTSAC\n",
    "import gym\n",
    "from metaworld_utils.meta_env import get_meta_env, generate_single_mt_env\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 11\n",
    "params = get_params(\"../meta_config/mt10/modular_4_4_2_128_reweight_rand.json\")\n",
    "\n",
    "# create policy\n",
    "device = torch.device(\"cuda:0\")\n",
    "#snapshot_path = \"../log/starter/mt10/11/model/model_pf_best.pth\"\n",
    "#params['net']['base_type']=networks.MLPBase\n",
    "#pf = policies.ModularGuassianGatedCascadeCondContPolicy(\n",
    "#        input_shape=env.observation_space.shape[0],\n",
    "#        em_input_shape=(np.prod(example_embedding.shape)),\n",
    "#        output_shape=2 * env.action_space.shape[0],\n",
    "#        **params['net'])\n",
    "#pf.load_state_dict(torch.load(snapshot_path, map_location='cpu'))\n",
    "#pf.to(device)\n",
    "#pf.eval()\n",
    "#env.eval()\n",
    "#\n",
    "#print(\"Module:\", pf.named_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs_space: Box(9,)\n",
      "Act_space: Box(4,)\n"
     ]
    }
   ],
   "source": [
    "# make mtenv\n",
    "meta_env, cls_dicts, cls_args = get_meta_env( params['env_name'], params['env'], params['meta_env'])\n",
    "tasks = list(cls_dicts.keys())\n",
    "example_embedding = meta_env.active_task_one_hot\n",
    "print(\"Obs_space:\" , meta_env.observation_space)\n",
    "print(\"Act_space:\", meta_env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 2]\n",
      "[[10.          3.          5.5       ]\n",
      " [ 1.          2.          2.33333333]\n",
      " [10.          0.         11.        ]]\n",
      "1.8611111111111114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 2], [1, 4, 2], [1, 0, 3],\n",
    "              [10, 2, 6], [10, 4, 5], [10, 0, 11]])\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit(X)\n",
    "print(kmeans.labels_)\n",
    "print(kmeans.cluster_centers_)\n",
    "print(kmeans.inertia_/X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reach-v1',\n",
      " 'push-v1',\n",
      " 'pick-place-v1',\n",
      " 'door-v1',\n",
      " 'drawer-open-v1',\n",
      " 'drawer-close-v1',\n",
      " 'button-press-topdown-v1',\n",
      " 'ped-insert-side-v1',\n",
      " 'window-open-v1',\n",
      " 'window-close-v1']\n"
     ]
    }
   ],
   "source": [
    "#choose a single task to evaluate on.\n",
    "pprint.pprint(tasks)\n",
    "env_id = tasks[8]\n",
    "env_args = {\n",
    "            \"task_cls\": cls_dicts[env_id],\n",
    "            \"task_args\": cls_args[env_id],\n",
    "            \"env_rank\": 8,\n",
    "            \"num_tasks\": meta_env.num_tasks,\n",
    "            \"max_obs_dim\": np.prod(meta_env.observation_space.shape),\n",
    "            \"env_params\": params[\"env\"],\n",
    "            \"meta_env_params\": params[\"meta_env\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval for timesteps\n",
    "qf = networks.FlattenModularGatedCascadeCondNet(\n",
    "        input_shape=meta_env.observation_space.shape[0] + meta_env.action_space.shape[0],\n",
    "        em_input_shape=np.prod(example_embedding.shape),\n",
    "        output_shape=1,\n",
    "        **params['net'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.99999999  -1.          -1.99999999 -29.89735285]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.49999999855730487"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "p = np.array([0.5, 0.5, 0.0, 0.0])\n",
    "q = np.array([0.25, 0.5, 0.25, 0.0])\n",
    "\n",
    "eps = 1.0e-9\n",
    "\n",
    "print(np.log2(q+eps))\n",
    "def KLDiv(p, q):\n",
    "    return np.sum(p * (np.log2(q+eps) - np.log2(p + eps)))\n",
    "\n",
    "KLDiv(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2754],\n",
      "        [0.1941],\n",
      "        [0.3364],\n",
      "        [0.1941]])\n",
      "tensor([-0.1645,  1.6118], grad_fn=<SplitBackward0>) tensor([0.2000, 0.1000], grad_fn=<SplitBackward0>)\n",
      "tensor([[ 0.4839,  1.0281],\n",
      "        [ 0.0355,  1.2168],\n",
      "        [ 0.6884,  1.3834],\n",
      "        [ 0.6309,  0.5829],\n",
      "        [ 0.6901,  1.1042],\n",
      "        [ 0.1278,  1.3686],\n",
      "        [ 0.6883, -3.1957],\n",
      "        [ 0.5765, -0.3208],\n",
      "        [ 0.6172,  1.2779],\n",
      "        [ 0.4589,  0.6360]], grad_fn=<SubBackward0>)\n",
      "tensor([0., 0.])\n",
      "tensor([ -50.0000, -100.0000])\n",
      "tensor([[  0.0000,   0.0000, -13.7711, -27.5423],\n",
      "        [  0.0000,   0.0000,  -9.7044, -19.4087],\n",
      "        [  0.0000,   0.0000, -16.8201, -33.6402],\n",
      "        [  0.0000,   0.0000,  -9.7044, -19.4087]])\n"
     ]
    }
   ],
   "source": [
    "# AFS\n",
    "xs = torch.Tensor([[1, 2, 0.2, 0.1],\n",
    "                   [-2, 1, 0.2, 0.1],\n",
    "                   [1, 2, 0.2, 0.1],\n",
    "                   [-2, 1, 0.2, 0.1]\n",
    "                   ])\n",
    "ws = torch.Tensor([0.4, 0.05, 0.6, 0.05])\n",
    "ws = torch.softmax(ws, -1).unsqueeze(-1)\n",
    "print(ws)\n",
    "xs.requires_grad = True; ws.requires_grad=True\n",
    "from torch.distributions import Normal\n",
    "##dis = Normal(mu, sigma)\n",
    "##action, z = dis.sample()\n",
    "##log_prob = dis.log_prob(\n",
    "##    action\n",
    "##)\n",
    "num_samples = 10\n",
    "\n",
    "\n",
    "mu, sigma = torch.split(torch.sum(ws * xs, dim=0), 2)\n",
    "print(mu, sigma)\n",
    "dist = Normal(mu, sigma)\n",
    "samples = dist.rsample((num_samples, ))\n",
    "\n",
    "log_probs = dist.log_prob(samples)\n",
    "print(log_probs)\n",
    "dist.scale.retain_grad()\n",
    "dist.loc.retain_grad()\n",
    "loss = log_probs.sum()\n",
    "loss.backward()\n",
    "g = ws.grad\n",
    "\n",
    "print(dist.loc.grad)\n",
    "print(dist.scale.grad)\n",
    "H = g@g.transpose(0, 1)/num_samples\n",
    "print(xs.grad)\n",
    "del ws, xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularGuassianSelectCascadeContPolicy(\n",
      "  (base): MLPBase(\n",
      "    (fc0): Linear(in_features=9, out_features=400, bias=True)\n",
      "    (fc1): Linear(in_features=400, out_features=400, bias=True)\n",
      "  )\n",
      "  (em_base): MLPBase(\n",
      "    (fc0): Linear(in_features=10, out_features=400, bias=True)\n",
      "  )\n",
      "  (module_0_0): Linear(in_features=400, out_features=128, bias=True)\n",
      "  (module_0_1): Linear(in_features=400, out_features=128, bias=True)\n",
      "  (module_0_2): Linear(in_features=400, out_features=128, bias=True)\n",
      "  (module_0_3): Linear(in_features=400, out_features=128, bias=True)\n",
      "  (module_1_0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_1_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_1_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_1_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_2_0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_2_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_2_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_2_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_3_0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_3_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_3_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (module_3_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (last): Linear(in_features=128, out_features=8, bias=True)\n",
      "  (gating_fc_0): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (gating_fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (select_fc_0): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (select_cond_fc1): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (select_fc_1): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (select_cond_fc2): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (select_fc_2): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (select_cond_fc3): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (select_fc_3): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchrl.policies as policies\n",
    "import torchrl.networks as networks\n",
    "SEED = 11\n",
    "params['net']['base_type']=networks.MLPBase\n",
    "pf = policies.ModularGuassianSelectCascadeContPolicy(\n",
    "        input_shape=9,\n",
    "        em_input_shape=(np.prod(example_embedding.shape)),\n",
    "        output_shape=2 * meta_env.action_space.shape[0],\n",
    "        **params['net'])\n",
    "pf.to(device)\n",
    "\n",
    "qf = networks.FlattenModularSelectCascadeCondNet(\n",
    "        input_shape=meta_env.observation_space.shape[0] + meta_env.action_space.shape[0],\n",
    "        em_input_shape=np.prod(example_embedding.shape),\n",
    "        output_shape=1,\n",
    "        **params['net'])\n",
    "qf.to(device)\n",
    "pf.train()\n",
    "qf.train()\n",
    "rews = []\n",
    "rew = 0\n",
    "\n",
    "env = generate_single_mt_env(**env_args)\n",
    "env.seed(SEED)\n",
    "\n",
    "# test env\n",
    "eval_ob = env.reset()\n",
    "try:\n",
    "    for i in range(10):\n",
    "        embedding_input = torch.zeros(env.num_tasks)\n",
    "        embedding_input[env_args[\"env_rank\"]] = 1\n",
    "        embedding_input = embedding_input.unsqueeze(0).to(device)\n",
    "        eval_ob = torch.Tensor( eval_ob ).to(device).unsqueeze(0)\n",
    "\n",
    "        # policy\n",
    "        out = pf.explore( eval_ob, embedding_input, return_weights = True)\n",
    "        act = out[\"action\"]\n",
    "\n",
    "        # q\n",
    "        q_pred = qf([eval_ob, act.unsqueeze(0)], embedding_input)\n",
    "        act = act.detach().cpu().numpy()\n",
    "\n",
    "        logits = out[\"general_weights\"]\n",
    "        eval_ob, r, done, info = env.step( act )\n",
    "        rew += r\n",
    "        rews.append(rew)\n",
    "        done = info[\"success\"]\n",
    "finally:\n",
    "    env.close()\n",
    "\n",
    "print(pf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoftModuleEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
