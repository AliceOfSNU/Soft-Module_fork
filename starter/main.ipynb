{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft-Module performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torchrl.policies as policies\n",
    "import torchrl.networks as networks\n",
    "from torchrl.utils import get_params\n",
    "from torchrl.algo import MTSAC\n",
    "from torchrl.replay_buffers.shared import AsyncSharedReplayBuffer\n",
    "from torchrl.collector.para.async_mt import AsyncMultiTaskParallelCollectorUniform\n",
    "import gym\n",
    "from metaworld_utils.meta_env import get_meta_env, generate_single_mt_env\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs_space: Box(9,)\n",
      "Act_space: Box(4,)\n",
      "Module: <bound method Module.named_modules of ModularGuassianGatedCascadeCondContPolicy(\n",
      "  (base): MLPBase(\n",
      "    (fc0): Linear(in_features=9, out_features=400, bias=True)\n",
      "    (fc1): Linear(in_features=400, out_features=400, bias=True)\n",
      "  )\n",
      "  (em_base): MLPBase(\n",
      "    (fc0): Linear(in_features=10, out_features=400, bias=True)\n",
      "  )\n",
      "  (module_0_0): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (module_0_1): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (module_1_0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (module_1_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (last): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (gating_fc_0): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (gating_fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (gating_weight_fc_0): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (gating_weight_cond_last): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (gating_weight_last): Linear(in_features=256, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "SEED = 11\n",
    "params = get_params(\"../meta_config/mt10/modular_2_2_2_256_reweight_rand.json\")\n",
    "\n",
    "# make mtenv\n",
    "env, cls_dicts, cls_args = get_meta_env( params['env_name'], params['env'], params['meta_env'])\n",
    "tasks = list(cls_dicts.keys())\n",
    "example_embedding = env.active_task_one_hot\n",
    "print(\"Obs_space:\" , env.observation_space)\n",
    "print(\"Act_space:\", env.action_space)\n",
    "\n",
    "# create policy\n",
    "device = torch.device(\"cuda:0\")\n",
    "snapshot_path = \"../log/starter/mt10/11/model/model_pf_best.pth\"\n",
    "params['net']['base_type']=networks.MLPBase\n",
    "pf = policies.ModularGuassianGatedCascadeCondContPolicy(\n",
    "        input_shape=env.observation_space.shape[0],\n",
    "        em_input_shape=(np.prod(example_embedding.shape)),\n",
    "        output_shape=2 * env.action_space.shape[0],\n",
    "        **params['net'])\n",
    "pf.load_state_dict(torch.load(snapshot_path, map_location='cpu'))\n",
    "pf.to(device)\n",
    "pf.eval()\n",
    "env.eval()\n",
    "\n",
    "print(\"Module:\", pf.named_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reach-v1',\n",
      " 'push-v1',\n",
      " 'pick-place-v1',\n",
      " 'door-v1',\n",
      " 'drawer-open-v1',\n",
      " 'drawer-close-v1',\n",
      " 'button-press-topdown-v1',\n",
      " 'ped-insert-side-v1',\n",
      " 'window-open-v1',\n",
      " 'window-close-v1']\n",
      "{'env_params': {'obs_norm': False, 'reward_scale': 1},\n",
      " 'env_rank': 5,\n",
      " 'max_obs_dim': 9,\n",
      " 'meta_env_params': {'obs_type': 'with_goal', 'random_init': True},\n",
      " 'num_tasks': 10,\n",
      " 'task_args': {'args': [],\n",
      "               'kwargs': {'obs_type': 'plain', 'random_init': True}},\n",
      " 'task_cls': <class 'metaworld.envs.mujoco.sawyer_xyz.sawyer_drawer_close.SawyerDrawerCloseEnv'>}\n",
      "Box(4,)\n",
      "Box(6,)\n",
      "[-0.03265199  0.51487863  0.23688568  0.07903633  0.49999998  0.09\n",
      "  0.07903633  0.69999998  0.04      ]\n"
     ]
    }
   ],
   "source": [
    "#choose a single task to evaluate on.\n",
    "pprint.pprint(tasks)\n",
    "env_id = tasks[5]\n",
    "env_args = {\n",
    "            \"task_cls\": cls_dicts[env_id],\n",
    "            \"task_args\": cls_args[env_id],\n",
    "            \"env_rank\": 5,\n",
    "            \"num_tasks\": env.num_tasks,\n",
    "            \"max_obs_dim\": np.prod(env.observation_space.shape),\n",
    "            \"env_params\": params[\"env\"],\n",
    "            \"meta_env_params\": params[\"meta_env\"]\n",
    "        }\n",
    "pprint.pprint(env_args)\n",
    "env = generate_single_mt_env(**env_args)\n",
    "env.seed(SEED)\n",
    "\n",
    "# test env\n",
    "example_ob = env.reset()\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(example_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "moving.. [ 0.71749854 -0.3827432  -0.64066875 -0.93301755]\n",
      "moving.. [ 0.24028979 -0.62976956 -0.11336626 -0.8342447 ]\n",
      "moving.. [ 0.00202824 -0.7172431   0.06591776 -0.72614825]\n",
      "moving.. [ 0.00358261 -0.71576416  0.04401302 -0.7354229 ]\n",
      "moving.. [ 0.00078825 -0.71581423  0.03266397 -0.7407523 ]\n",
      "moving.. [ 3.6201809e-04 -7.1585149e-01  2.3268715e-02 -7.4440801e-01]\n",
      "moving.. [ 3.5193004e-04 -7.1572053e-01  1.6463466e-02 -7.4701065e-01]\n",
      "moving.. [ 2.4689920e-04 -7.1565342e-01  1.1746833e-02 -7.4881101e-01]\n",
      "moving.. [ 1.6042031e-04 -7.1560335e-01  8.3354926e-03 -7.5008130e-01]\n",
      "moving.. [ 1.1291541e-04 -7.1556449e-01  5.9105488e-03 -7.5097907e-01]\n",
      "moving.. [ 7.9924241e-05 -7.1553707e-01  4.1921837e-03 -7.5161326e-01]\n",
      "moving.. [ 5.6521967e-05 -7.1551776e-01  2.9741414e-03 -7.5206184e-01]\n",
      "moving.. [ 4.1591004e-05 -7.1550214e-01  2.1184701e-03 -7.5237530e-01]\n",
      "moving.. [ 2.8962269e-05 -7.1549177e-01  1.5100057e-03 -7.5259823e-01]\n",
      "moving.. [ 2.0148233e-05 -7.1548456e-01  1.0765390e-03 -7.5275719e-01]\n",
      "moving.. [ 1.4225021e-05 -7.1547943e-01  7.6739240e-04 -7.5287056e-01]\n",
      "moving.. [ 1.0395423e-05 -7.1547568e-01  5.4658711e-04 -7.5295150e-01]\n",
      "moving.. [ 7.2214752e-06 -7.1547312e-01  3.8954380e-04 -7.5300908e-01]\n",
      "moving.. [ 5.2992254e-06 -7.1547127e-01  2.7743494e-04 -7.5305015e-01]\n",
      "moving.. [ 3.8687140e-06 -7.1546984e-01  1.9759452e-04 -7.5307935e-01]\n",
      "moving.. [ 2.6617199e-06 -7.1546888e-01  1.4081364e-04 -7.5310016e-01]\n",
      "moving.. [ 1.9241124e-06 -7.1546817e-01  1.0031974e-04 -7.5311494e-01]\n",
      "moving.. [ 1.2833625e-06 -7.1546781e-01  7.1508344e-05 -7.5312549e-01]\n",
      "moving.. [ 9.3318522e-07 -7.1546745e-01  5.0974544e-05 -7.5313312e-01]\n",
      "moving.. [ 5.6810677e-07 -7.1546721e-01  3.6490615e-05 -7.5313836e-01]\n",
      "moving.. [ 5.9045851e-07 -7.1546698e-01  2.5858637e-05 -7.5314224e-01]\n",
      "moving.. [ 4.7869980e-07 -7.1546686e-01  1.8355902e-05 -7.5314498e-01]\n",
      "moving.. [ 1.2107193e-07 -7.1546686e-01  1.3215002e-05 -7.5314689e-01]\n",
      "moving.. [ 1.13621354e-07 -7.15466738e-01  9.34069976e-06 -7.53148317e-01]\n",
      "moving.. [ 1.2852252e-07 -7.1546662e-01  6.6733919e-06 -7.5314927e-01]\n",
      "moving.. [ 5.4016709e-08 -7.1546662e-01  4.7064386e-06 -7.5315005e-01]\n",
      "moving.. [ 8.3819032e-08 -7.1546656e-01  3.4398399e-06 -7.5315046e-01]\n",
      "moving.. [-5.5879354e-09 -7.1546662e-01  2.4191104e-06 -7.5315076e-01]\n",
      "moving.. [-3.5390258e-08 -7.1546662e-01  1.7783605e-06 -7.5315112e-01]\n",
      "moving.. [ 8.3819032e-08 -7.1546656e-01  1.2344681e-06 -7.5315130e-01]\n",
      "moving.. [-1.09896064e-07 -7.15466619e-01  9.06642526e-07 -7.53151417e-01]\n",
      "moving.. [-7.264316e-08 -7.154665e-01  6.533228e-07 -7.531515e-01]\n",
      "moving.. [-1.3038516e-08 -7.1546650e-01  3.9255247e-07 -7.5315154e-01]\n",
      "moving.. [-5.5879354e-09 -7.1546650e-01  3.3294782e-07 -7.5315154e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546650e-01  1.7648563e-07 -7.5315160e-01]\n",
      "moving.. [-5.5879354e-09 -7.1546650e-01  1.2433156e-07 -7.5315160e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n",
      "moving.. [ 2.4214387e-08 -7.1546656e-01  5.1222742e-09 -7.5315166e-01]\n"
     ]
    }
   ],
   "source": [
    "#eval for timesteps\n",
    "eval_ob = env.reset()\n",
    "rew = 0\n",
    "done = False\n",
    "imgs = []\n",
    "try:\n",
    "    for i in range(1000):\n",
    "        embedding_input = torch.zeros(env.num_tasks)\n",
    "        embedding_input[env_args[\"env_rank\"]] = 1\n",
    "        embedding_input = embedding_input.unsqueeze(0).to(device)\n",
    "        act = pf.eval_act( torch.Tensor( eval_ob ).to(device).unsqueeze(0), embedding_input)\n",
    "        eval_ob, r, done, info = env.step( act )\n",
    "        rew += r\n",
    "        imgs.append(env.render('rgb_array'))\n",
    "        done = info[\"success\"]\n",
    "        if i % 20 == 0:\n",
    "            print(\"moving..\", act)\n",
    "finally:\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave(\"close-soft-module1.gif\", [np.array(img) for i, img in enumerate(imgs) if i%2 == 0], duration=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoftModuleEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
